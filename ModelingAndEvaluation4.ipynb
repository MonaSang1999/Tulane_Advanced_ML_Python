{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "103b0687-8fdb-4701-a6ed-2ca4e3a1b464",
   "metadata": {
    "id": "vqX-wah5phgH"
   },
   "source": [
    "# Modeling and Evaluation with scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d14d16-4c23-4c85-82a0-8734f6458dea",
   "metadata": {
    "id": "Mp7rXXdFtFHB"
   },
   "source": [
    "# Part 4: Data wrangling and model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62025832-8355-4e30-b9d3-ca5c83da2910",
   "metadata": {
    "id": "Mp7rXXdFtFHB"
   },
   "source": [
    "Some data wrangling operations, such as converting data to formats acceptable to scikit-learn, dealing with erroneous and missing data, are necessary before we can conduct supervised learning. \n",
    "\n",
    "Some other data wrangling operations are optional, albeit may affect the performance of a trained model. In this part of the lecture, we consider the following two commonly-seen data wrangling operations and see how they may or may not affect model performance.\n",
    "\n",
    "+ ***balancing data w.r.t. the target variable***\n",
    "+ ***data normalization/standardization***\n",
    "    \n",
    "We use the LendingClub dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eecb729f-850b-495e-a484-b1bd095f4cbd",
   "metadata": {
    "id": "b8AiVuH_phgT"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('max_columns', 50)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa57c2d0-7da4-4b26-be48-2325ab3065ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the LendingClub dataset\n",
    "\n",
    "df = pd.read_csv('LendingClub.csv')\n",
    "\n",
    "# Convert categorical variable \"purpose\" to dummies, and drop the most frequent dummy\n",
    "df = pd.get_dummies(df, columns=['purpose']).drop(columns=['purpose_debt_consolidation'])\n",
    "\n",
    "X = df.drop(columns=['not_fully_paid'])\n",
    "y = df['not_fully_paid']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=365)\n",
    "X_train = X_train.copy()\n",
    "X_test = X_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "613e8e7e-b91b-4a0f-8c7b-2d5cb80f86a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.839946\n",
       "1    0.160054\n",
       "Name: not_fully_paid, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41cf52f8-80cf-4185-ae26-b909be3bfc5e",
   "metadata": {
    "id": "pm9X6Yu2ovyz"
   },
   "source": [
    "## Dealing with severely unbalanced data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a78a74-6b8a-4ba1-8439-463f2a75dfe6",
   "metadata": {},
   "source": [
    "### Unbalanced data and the resulting bias in predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f2a2d14c-b831-46d3-935c-afeb2174dc3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is: 84.39%\n",
      "The confusion matrix is:\n",
      "[[1616    0]\n",
      " [ 299    1]]\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(penalty='none', max_iter=1000)\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "y_predict = clf.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_predict).round(4)\n",
    "print(f\"The accuracy is: {accuracy:.2%}\")\n",
    "print(\"The confusion matrix is:\")\n",
    "cm = confusion_matrix(y_test, y_predict)\n",
    "print(cm)\n",
    "\n",
    "# save the results for later comparison\n",
    "clf_lr = clf\n",
    "accuracy_lr = accuracy\n",
    "cm_lr = cm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f7b5ee-3338-49c0-a658-a44a9b834048",
   "metadata": {},
   "source": [
    "The accuracy above, while pretty high, is misleading because we actually got an extremely biased trained model: this trained model almost always predicts that borrowers will not default, as evident from the confusion matrix. \n",
    "\n",
    "This extremely biased trained model is triggered by the severely unbalanced dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "819d437f-3911-4995-bf38-e9d66413159d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.843424\n",
       "1    0.156576\n",
       "Name: not_fully_paid, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33ee5ae9-5d9b-4271-8fcf-a948af325505",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    8045\n",
       "1    1533\n",
       "Name: not_fully_paid, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470f44eb-6fdc-4d0b-8962-b75bb8f28559",
   "metadata": {
    "id": "pm9X6Yu2ovyz"
   },
   "source": [
    "### Options for dealing with severely unbalanced data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209c35fa-a699-4261-a01d-dca05e9cf085",
   "metadata": {
    "id": "0T3JL5D9phgV"
   },
   "source": [
    "+ **Option 1. Re-sampling the data to make it balanced.** This can be done in two ways:\n",
    "  + **undersampling** the majority class\n",
    "    + this is the usual choice when we have large enough data\n",
    "  + **oversampling** the minority class\n",
    "    + it may cause the [data leakage](https://towardsdatascience.com/data-leakage-in-machine-learning-10bdd3eec742) problem, thus should be avoided unless the data size is too small\n",
    "+ **Option 2. Do not use \"accuracy\" as the performance metric.** Instead, \n",
    "  + use alternative metrics that can give different weight to different classes of the target, e.g., counts '1' more heavily than '0' in the target of the LendingClub dataset (to be discussed in the next lecture)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acaadb6e-0b62-41a7-8bb9-d0575b9256e6",
   "metadata": {
    "id": "NSKsulLJRcs5"
   },
   "source": [
    "### Undersampling the majority class\n",
    "\n",
    "The function for this is `sklearn.utils.resample()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c802bc9-f07e-4f70-b285-1b45f9af2450",
   "metadata": {
    "id": "wLIv9mpVphgW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The majority class contains 8045 records. \n",
      "The minority class contains 1533 records. \n"
     ]
    }
   ],
   "source": [
    "# First, separate the classes, where we already know 'not_fully_paid==0' is the majority class\n",
    "df_0 = df[df.not_fully_paid==0]\n",
    "df_1 = df[df.not_fully_paid==1]\n",
    "\n",
    "# Remember the sizes of the two classes\n",
    "n_majority_class = df_0.shape[0]\n",
    "n_minority_class = df_1.shape[0]\n",
    "print(f\"The majority class contains {n_majority_class} records. \\nThe minority class contains {n_minority_class} records. \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "184fd4d1-f263-4d46-87ef-518a5141bb0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1533"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_minority_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33371261-43ff-4447-9b56-f0e34dba46d9",
   "metadata": {
    "id": "gMAmb7rMzqIl"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1533, 19)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "# undersample the majority class\n",
    "df_0_undersampled = resample(df_0, replace=False, \n",
    "                             n_samples=n_minority_class, \n",
    "                             random_state=1234)\n",
    "df_0_undersampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b876d9d-d09e-499d-8e89-91cf93270603",
   "metadata": {
    "id": "gMAmb7rMzqIl"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8045, 19)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# oversample the minority class\n",
    "# bootstraping\n",
    "\n",
    "df_1_oversampled = resample(df_1, replace=True, \n",
    "                             n_samples=n_majority_class, \n",
    "                             random_state=1234)\n",
    "df_1_oversampled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9bc610-56c0-4d66-a5a7-8f01930d2393",
   "metadata": {
    "id": "nGRI_vGou5EH"
   },
   "source": [
    "### Combining the two classes into a single (resampled) dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "821caf9a-2ac7-4733-909b-c9216c7ff4f8",
   "metadata": {
    "id": "IgdJz3QwzlC5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1533\n",
       "1    1533\n",
       "Name: not_fully_paid, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_balanced = pd.concat([df_0_undersampled, df_1])\n",
    "df_balanced.not_fully_paid.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9e3b67d1-9d85-40e8-8bfd-98b38666774f",
   "metadata": {
    "id": "kfQ9RZiIphgX"
   },
   "outputs": [],
   "source": [
    "# Save the balanced data for future use\n",
    "df_balanced.to_csv('LendingClub_balanced.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bced376-4583-4c8c-8ad3-bbf24c4031df",
   "metadata": {
    "id": "JLddQYvlsb7C"
   },
   "source": [
    "### Comments on oversampling\n",
    "\n",
    "The reason it should be avoided when possible: the the [data leakage](https://towardsdatascience.com/data-leakage-in-machine-learning-10bdd3eec742) problem.\n",
    "\n",
    "However, if you have to use it because the size of the minority class is too small, here are a few hints:\n",
    "+ make sure you do `train_test_split()` *before* oversampling (why?)\n",
    "+ ways to oversample:\n",
    "  + Use [bootstrapping](https://en.wikipedia.org/wiki/Bootstrapping_(statistics)), a.k.a. `resample()` with the option `replace=True`.\n",
    "  + Use [`imblearn.over_sampling.SMOTE`](https://imbalanced-learn.org/stable/over_sampling.html) -- a k-NN inspired method to create synthetic records\n",
    "    + [A nice tutorial on SMOTE](https://machinelearningmastery.com/smote-oversampling-for-imbalanced-classification/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c386e96-b73c-44a1-9e66-4a73a970a94d",
   "metadata": {
    "id": "w8VGfXVI0RT8"
   },
   "source": [
    "### Splitting this balanced data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9922db9b-3320-481f-a7d9-797d07bb3da1",
   "metadata": {
    "id": "zIFrz8Y3d2O_"
   },
   "outputs": [],
   "source": [
    "X = df_balanced.drop(columns=['not_fully_paid'])\n",
    "y = df_balanced['not_fully_paid']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=365)\n",
    "X_train = X_train.copy()\n",
    "X_test = X_test.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4192db9c-8252-4140-9a44-9db3d299e892",
   "metadata": {
    "id": "w8VGfXVI0RT8"
   },
   "source": [
    "### Training the logistic regression model over this balanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a57a5afb-62af-4f4b-9a1f-4d714fe18271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is: 53.58%\n",
      "The confusion matrix is:\n",
      "[[172 126]\n",
      " [159 157]]\n"
     ]
    }
   ],
   "source": [
    "clf.fit(X_train,y_train)\n",
    "\n",
    "y_predict = clf.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_predict).round(4)\n",
    "print(f\"The accuracy is: {accuracy:.2%}\")\n",
    "print(\"The confusion matrix is:\")\n",
    "cm = confusion_matrix(y_test, y_predict)\n",
    "print(cm)\n",
    "\n",
    "# save the results for later comparison\n",
    "clf_lr = clf\n",
    "accuracy_lr = accuracy\n",
    "cm_lr = cm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691bfc86-e5f7-48b4-a578-0fcf35170825",
   "metadata": {},
   "source": [
    "As shown above, the predictions are no longer extremely biased."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d499551-c1c7-4ba9-9097-364bd6e9823a",
   "metadata": {
    "id": "pm9X6Yu2ovyz"
   },
   "source": [
    "## Normalize/standardize the data\n",
    "\n",
    "Recall that: \"normalize\" --> [0,1], and \"standardize\" --> mean 0 and std 1.\n",
    "\n",
    "The LendingClub dataset consists of columns of varying scales. In addition, some columns are significantly skewed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "59d85338-4ec5-472c-9b0e-0ab7eac91434",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>credit_policy</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>log_annual_inc</th>\n",
       "      <th>dti</th>\n",
       "      <th>fico</th>\n",
       "      <th>days_with_cr_line</th>\n",
       "      <th>revol_bal</th>\n",
       "      <th>revol_util</th>\n",
       "      <th>inq_last_6mths</th>\n",
       "      <th>delinq_2yrs</th>\n",
       "      <th>pub_rec</th>\n",
       "      <th>purpose_all_other</th>\n",
       "      <th>purpose_credit_card</th>\n",
       "      <th>purpose_educational</th>\n",
       "      <th>purpose_home_improvement</th>\n",
       "      <th>purpose_major_purchase</th>\n",
       "      <th>purpose_small_business</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.743883</td>\n",
       "      <td>0.126485</td>\n",
       "      <td>330.044372</td>\n",
       "      <td>10.928757</td>\n",
       "      <td>12.788018</td>\n",
       "      <td>705.790783</td>\n",
       "      <td>4543.281522</td>\n",
       "      <td>19162.296493</td>\n",
       "      <td>48.881656</td>\n",
       "      <td>1.923736</td>\n",
       "      <td>0.167618</td>\n",
       "      <td>0.077488</td>\n",
       "      <td>0.249592</td>\n",
       "      <td>0.122349</td>\n",
       "      <td>0.035481</td>\n",
       "      <td>0.073409</td>\n",
       "      <td>0.040375</td>\n",
       "      <td>0.084421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.436576</td>\n",
       "      <td>0.026826</td>\n",
       "      <td>215.253362</td>\n",
       "      <td>0.641827</td>\n",
       "      <td>6.987826</td>\n",
       "      <td>37.485151</td>\n",
       "      <td>2453.147008</td>\n",
       "      <td>44268.837690</td>\n",
       "      <td>29.295286</td>\n",
       "      <td>2.633675</td>\n",
       "      <td>0.553948</td>\n",
       "      <td>0.271957</td>\n",
       "      <td>0.432865</td>\n",
       "      <td>0.327755</td>\n",
       "      <td>0.185030</td>\n",
       "      <td>0.260861</td>\n",
       "      <td>0.196878</td>\n",
       "      <td>0.278075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>skew</th>\n",
       "      <td>-1.118162</td>\n",
       "      <td>0.147838</td>\n",
       "      <td>0.846862</td>\n",
       "      <td>0.025453</td>\n",
       "      <td>-0.016562</td>\n",
       "      <td>0.595084</td>\n",
       "      <td>1.051591</td>\n",
       "      <td>11.791871</td>\n",
       "      <td>-0.021394</td>\n",
       "      <td>3.537308</td>\n",
       "      <td>6.176599</td>\n",
       "      <td>3.343906</td>\n",
       "      <td>1.157923</td>\n",
       "      <td>2.306349</td>\n",
       "      <td>5.025096</td>\n",
       "      <td>3.273309</td>\n",
       "      <td>4.672950</td>\n",
       "      <td>2.991415</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      credit_policy  int_rate  installment  log_annual_inc        dti  \\\n",
       "mean       0.743883  0.126485   330.044372       10.928757  12.788018   \n",
       "std        0.436576  0.026826   215.253362        0.641827   6.987826   \n",
       "skew      -1.118162  0.147838     0.846862        0.025453  -0.016562   \n",
       "\n",
       "            fico  days_with_cr_line     revol_bal  revol_util  inq_last_6mths  \\\n",
       "mean  705.790783        4543.281522  19162.296493   48.881656        1.923736   \n",
       "std    37.485151        2453.147008  44268.837690   29.295286        2.633675   \n",
       "skew    0.595084           1.051591     11.791871   -0.021394        3.537308   \n",
       "\n",
       "      delinq_2yrs   pub_rec  purpose_all_other  purpose_credit_card  \\\n",
       "mean     0.167618  0.077488           0.249592             0.122349   \n",
       "std      0.553948  0.271957           0.432865             0.327755   \n",
       "skew     6.176599  3.343906           1.157923             2.306349   \n",
       "\n",
       "      purpose_educational  purpose_home_improvement  purpose_major_purchase  \\\n",
       "mean             0.035481                  0.073409                0.040375   \n",
       "std              0.185030                  0.260861                0.196878   \n",
       "skew             5.025096                  3.273309                4.672950   \n",
       "\n",
       "      purpose_small_business  \n",
       "mean                0.084421  \n",
       "std                 0.278075  \n",
       "skew                2.991415  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.agg(['mean','std','skew'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc85f2e6-367b-4d68-b8e0-5173b16f47b6",
   "metadata": {},
   "source": [
    "Variables of varying scales, and skewed variables, are commonly seen in business datasets. \n",
    "+ E.g., salary is in the tens of thousands, while age is usually in two digits\n",
    "+ E.g., monetary variables (salary, spending, ...) are often right skewed "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c472ed52-2a74-469c-8c79-1243c692be2d",
   "metadata": {},
   "source": [
    "### *Do we need to normalize/standardize the data?*\n",
    "\n",
    "Nowadays, almost always **yes** because:\n",
    "+ Many learning algorithms are sensitive to varying data scales (e.g., kNN, SVM) or varying data distribution shapes (e.g., regression)\n",
    "+ **Regularization** is heavily used in modern machine learning. And regularization does NOT work without data normalization/stanardization\n",
    "    + See these two brief posts on the concept of regularization: [Over-fitting and Regularization](https://towardsdatascience.com/over-fitting-and-regularization-64d16100f45c), [L1 and L2 Regularization Methods](https://towardsdatascience.com/l1-and-l2-regularization-methods-ce25e7fc831c)\n",
    "\n",
    "Tree-based classifiers are an exception because they don't compare column values when splitting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6e3664-e189-4236-8107-ad8fc6c8e0c7",
   "metadata": {},
   "source": [
    "### Manually performing data normalization/standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2a8706c5-2158-4690-9451-c9aec84bb52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a copy, as later we'll also try another standardization method\n",
    "X_train_std_manual = X_train.copy()\n",
    "X_test_std_manual = X_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2d3a1e7a-27a6-4bad-b03b-3fd91cbfb8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below we normalize/standardize some input columns\n",
    "# Remember we need to work on both train and test datasets\n",
    "# In practice, remember to update your data description file afterwards!\n",
    "\n",
    "for x in [X_train_std_manual, X_test_std_manual]:\n",
    "    x['installment1000'] = x.installment / 1000\n",
    "    x.drop('installment', axis=1, inplace=True)\n",
    "\n",
    "    x['fico_ratio'] = x.fico / 850\n",
    "    x.drop('fico', axis=1, inplace=True)\n",
    "\n",
    "    x['decades_with_cr_line'] = x.days_with_cr_line / 3650\n",
    "    x.drop('days_with_cr_line', axis=1, inplace=True)\n",
    "\n",
    "    x['log_revol_bal'] = np.log(x.revol_bal + 1)\n",
    "    x.drop('revol_bal', axis=1, inplace=True)\n",
    "\n",
    "    x.revol_util = x.revol_util / 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2347eb8c-6397-497a-89ca-d4859d94959c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>credit_policy</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>log_annual_inc</th>\n",
       "      <th>dti</th>\n",
       "      <th>revol_util</th>\n",
       "      <th>inq_last_6mths</th>\n",
       "      <th>delinq_2yrs</th>\n",
       "      <th>pub_rec</th>\n",
       "      <th>purpose_all_other</th>\n",
       "      <th>purpose_credit_card</th>\n",
       "      <th>purpose_educational</th>\n",
       "      <th>purpose_home_improvement</th>\n",
       "      <th>purpose_major_purchase</th>\n",
       "      <th>purpose_small_business</th>\n",
       "      <th>installment1000</th>\n",
       "      <th>fico_ratio</th>\n",
       "      <th>decades_with_cr_line</th>\n",
       "      <th>log_revol_bal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.743883</td>\n",
       "      <td>0.126485</td>\n",
       "      <td>10.928757</td>\n",
       "      <td>12.788018</td>\n",
       "      <td>0.488817</td>\n",
       "      <td>1.923736</td>\n",
       "      <td>0.167618</td>\n",
       "      <td>0.077488</td>\n",
       "      <td>0.249592</td>\n",
       "      <td>0.122349</td>\n",
       "      <td>0.035481</td>\n",
       "      <td>0.073409</td>\n",
       "      <td>0.040375</td>\n",
       "      <td>0.084421</td>\n",
       "      <td>0.330044</td>\n",
       "      <td>0.830342</td>\n",
       "      <td>1.244735</td>\n",
       "      <td>8.650228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.436576</td>\n",
       "      <td>0.026826</td>\n",
       "      <td>0.641827</td>\n",
       "      <td>6.987826</td>\n",
       "      <td>0.292953</td>\n",
       "      <td>2.633675</td>\n",
       "      <td>0.553948</td>\n",
       "      <td>0.271957</td>\n",
       "      <td>0.432865</td>\n",
       "      <td>0.327755</td>\n",
       "      <td>0.185030</td>\n",
       "      <td>0.260861</td>\n",
       "      <td>0.196878</td>\n",
       "      <td>0.278075</td>\n",
       "      <td>0.215253</td>\n",
       "      <td>0.044100</td>\n",
       "      <td>0.672095</td>\n",
       "      <td>2.202951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>skew</th>\n",
       "      <td>-1.118162</td>\n",
       "      <td>0.147838</td>\n",
       "      <td>0.025453</td>\n",
       "      <td>-0.016562</td>\n",
       "      <td>-0.021394</td>\n",
       "      <td>3.537308</td>\n",
       "      <td>6.176599</td>\n",
       "      <td>3.343906</td>\n",
       "      <td>1.157923</td>\n",
       "      <td>2.306349</td>\n",
       "      <td>5.025096</td>\n",
       "      <td>3.273309</td>\n",
       "      <td>4.672950</td>\n",
       "      <td>2.991415</td>\n",
       "      <td>0.846862</td>\n",
       "      <td>0.595084</td>\n",
       "      <td>1.051591</td>\n",
       "      <td>-2.108405</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      credit_policy  int_rate  log_annual_inc        dti  revol_util  \\\n",
       "mean       0.743883  0.126485       10.928757  12.788018    0.488817   \n",
       "std        0.436576  0.026826        0.641827   6.987826    0.292953   \n",
       "skew      -1.118162  0.147838        0.025453  -0.016562   -0.021394   \n",
       "\n",
       "      inq_last_6mths  delinq_2yrs   pub_rec  purpose_all_other  \\\n",
       "mean        1.923736     0.167618  0.077488           0.249592   \n",
       "std         2.633675     0.553948  0.271957           0.432865   \n",
       "skew        3.537308     6.176599  3.343906           1.157923   \n",
       "\n",
       "      purpose_credit_card  purpose_educational  purpose_home_improvement  \\\n",
       "mean             0.122349             0.035481                  0.073409   \n",
       "std              0.327755             0.185030                  0.260861   \n",
       "skew             2.306349             5.025096                  3.273309   \n",
       "\n",
       "      purpose_major_purchase  purpose_small_business  installment1000  \\\n",
       "mean                0.040375                0.084421         0.330044   \n",
       "std                 0.196878                0.278075         0.215253   \n",
       "skew                4.672950                2.991415         0.846862   \n",
       "\n",
       "      fico_ratio  decades_with_cr_line  log_revol_bal  \n",
       "mean    0.830342              1.244735       8.650228  \n",
       "std     0.044100              0.672095       2.202951  \n",
       "skew    0.595084              1.051591      -2.108405  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the summary statistics of the transformed data\n",
    "X_train_std_manual.agg(['mean','std','skew'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cd7272f6-f651-43b0-b3e9-39d5f4375f47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is: 59.28%\n",
      "The confusion matrix is:\n",
      "[[178 120]\n",
      " [130 186]]\n"
     ]
    }
   ],
   "source": [
    "# Now let's run the logistic regression again with this transformed data\n",
    "clf.fit(X_train_std_manual,y_train)\n",
    "\n",
    "y_predict = clf.predict(X_test_std_manual)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_predict).round(4)\n",
    "print(f\"The accuracy is: {accuracy:.2%}\")\n",
    "print(\"The confusion matrix is:\")\n",
    "cm = confusion_matrix(y_test, y_predict)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ac9441-8c54-4701-a489-e9e6979c0ab9",
   "metadata": {},
   "source": [
    "### Automatically performing data normalization/standardization\n",
    "\n",
    "We can automatically standardize data using `sklearn.preprocessing.StandardScaler`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e82de73-acc0-4cce-9e3b-013e97fcdcc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a copy, as later we'll also try another standardization method\n",
    "X_train_std_auto = X_train.copy()\n",
    "X_test_std_auto = X_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de2db7b6-4071-4ffe-8270-86dd69850460",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "34846484-0e31-4778-bef3-d58bb96e7f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warning: we don't want to standardize any categorical columns!\n",
    "# Therefore, let's pick out only the numerical ones.\n",
    "num_columns = ['int_rate', 'installment', 'log_annual_inc', 'dti', \n",
    "               'fico', 'days_with_cr_line', 'revol_bal', 'revol_util',\n",
    "               'inq_last_6mths', 'delinq_2yrs', 'pub_rec']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b824ddf3-55cd-47f3-87f9-be566026ecc6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit(X_train_std_auto[num_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1bdf7782-72ae-4f07-947e-69e108dd391f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.22602793e-01 3.18479901e+02 1.09329970e+01 1.25938684e+01\n",
      " 7.10858001e+02 4.57314781e+03 1.68191928e+04 4.69906630e+01\n",
      " 1.57478465e+00 1.66405638e-01 6.08196293e-02]\n"
     ]
    }
   ],
   "source": [
    "print(scaler.mean_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "09ff8c92-ba93-4ef7-9915-75dde540a96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_std_auto[num_columns] = scaler.transform(X_train_std_auto[num_columns])\n",
    "X_test_std_auto[num_columns] = scaler.transform(X_test_std_auto[num_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9891a8f0-2e20-4ec4-ab74-a38bed53de31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>credit_policy</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>log_annual_inc</th>\n",
       "      <th>dti</th>\n",
       "      <th>fico</th>\n",
       "      <th>days_with_cr_line</th>\n",
       "      <th>revol_bal</th>\n",
       "      <th>revol_util</th>\n",
       "      <th>inq_last_6mths</th>\n",
       "      <th>delinq_2yrs</th>\n",
       "      <th>pub_rec</th>\n",
       "      <th>purpose_all_other</th>\n",
       "      <th>purpose_credit_card</th>\n",
       "      <th>purpose_educational</th>\n",
       "      <th>purpose_home_improvement</th>\n",
       "      <th>purpose_major_purchase</th>\n",
       "      <th>purpose_small_business</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.743883</td>\n",
       "      <td>3.821712e-16</td>\n",
       "      <td>-1.505049e-16</td>\n",
       "      <td>1.596512e-16</td>\n",
       "      <td>-1.014686e-16</td>\n",
       "      <td>1.515463e-16</td>\n",
       "      <td>2.491097e-16</td>\n",
       "      <td>-1.684351e-17</td>\n",
       "      <td>-8.575703e-17</td>\n",
       "      <td>-1.886292e-16</td>\n",
       "      <td>-3.889403e-17</td>\n",
       "      <td>-3.164951e-17</td>\n",
       "      <td>0.249592</td>\n",
       "      <td>0.122349</td>\n",
       "      <td>0.035481</td>\n",
       "      <td>0.073409</td>\n",
       "      <td>0.040375</td>\n",
       "      <td>0.084421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.436576</td>\n",
       "      <td>1.000204e+00</td>\n",
       "      <td>1.000204e+00</td>\n",
       "      <td>1.000204e+00</td>\n",
       "      <td>1.000204e+00</td>\n",
       "      <td>1.000204e+00</td>\n",
       "      <td>1.000204e+00</td>\n",
       "      <td>1.000204e+00</td>\n",
       "      <td>1.000204e+00</td>\n",
       "      <td>1.000204e+00</td>\n",
       "      <td>1.000204e+00</td>\n",
       "      <td>1.000204e+00</td>\n",
       "      <td>0.432865</td>\n",
       "      <td>0.327755</td>\n",
       "      <td>0.185030</td>\n",
       "      <td>0.260861</td>\n",
       "      <td>0.196878</td>\n",
       "      <td>0.278075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>skew</th>\n",
       "      <td>-1.118162</td>\n",
       "      <td>1.478385e-01</td>\n",
       "      <td>8.468624e-01</td>\n",
       "      <td>2.545270e-02</td>\n",
       "      <td>-1.656245e-02</td>\n",
       "      <td>5.950842e-01</td>\n",
       "      <td>1.051591e+00</td>\n",
       "      <td>1.179187e+01</td>\n",
       "      <td>-2.139405e-02</td>\n",
       "      <td>3.537308e+00</td>\n",
       "      <td>6.176599e+00</td>\n",
       "      <td>3.343906e+00</td>\n",
       "      <td>1.157923</td>\n",
       "      <td>2.306349</td>\n",
       "      <td>5.025096</td>\n",
       "      <td>3.273309</td>\n",
       "      <td>4.672950</td>\n",
       "      <td>2.991415</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      credit_policy      int_rate   installment  log_annual_inc           dti  \\\n",
       "mean       0.743883  3.821712e-16 -1.505049e-16    1.596512e-16 -1.014686e-16   \n",
       "std        0.436576  1.000204e+00  1.000204e+00    1.000204e+00  1.000204e+00   \n",
       "skew      -1.118162  1.478385e-01  8.468624e-01    2.545270e-02 -1.656245e-02   \n",
       "\n",
       "              fico  days_with_cr_line     revol_bal    revol_util  \\\n",
       "mean  1.515463e-16       2.491097e-16 -1.684351e-17 -8.575703e-17   \n",
       "std   1.000204e+00       1.000204e+00  1.000204e+00  1.000204e+00   \n",
       "skew  5.950842e-01       1.051591e+00  1.179187e+01 -2.139405e-02   \n",
       "\n",
       "      inq_last_6mths   delinq_2yrs       pub_rec  purpose_all_other  \\\n",
       "mean   -1.886292e-16 -3.889403e-17 -3.164951e-17           0.249592   \n",
       "std     1.000204e+00  1.000204e+00  1.000204e+00           0.432865   \n",
       "skew    3.537308e+00  6.176599e+00  3.343906e+00           1.157923   \n",
       "\n",
       "      purpose_credit_card  purpose_educational  purpose_home_improvement  \\\n",
       "mean             0.122349             0.035481                  0.073409   \n",
       "std              0.327755             0.185030                  0.260861   \n",
       "skew             2.306349             5.025096                  3.273309   \n",
       "\n",
       "      purpose_major_purchase  purpose_small_business  \n",
       "mean                0.040375                0.084421  \n",
       "std                 0.196878                0.278075  \n",
       "skew                4.672950                2.991415  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify that standardization is done\n",
    "X_train_std_auto.agg(['mean','std','skew'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ba7d3c17-43d6-49a1-8e41-cd22006fe438",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>credit_policy</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>log_annual_inc</th>\n",
       "      <th>dti</th>\n",
       "      <th>fico</th>\n",
       "      <th>days_with_cr_line</th>\n",
       "      <th>revol_bal</th>\n",
       "      <th>revol_util</th>\n",
       "      <th>inq_last_6mths</th>\n",
       "      <th>delinq_2yrs</th>\n",
       "      <th>pub_rec</th>\n",
       "      <th>purpose_all_other</th>\n",
       "      <th>purpose_credit_card</th>\n",
       "      <th>purpose_educational</th>\n",
       "      <th>purpose_home_improvement</th>\n",
       "      <th>purpose_major_purchase</th>\n",
       "      <th>purpose_small_business</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2790</th>\n",
       "      <td>1</td>\n",
       "      <td>1.249599</td>\n",
       "      <td>0.916854</td>\n",
       "      <td>-0.169830</td>\n",
       "      <td>-0.696785</td>\n",
       "      <td>-0.101148</td>\n",
       "      <td>-0.164444</td>\n",
       "      <td>-0.299240</td>\n",
       "      <td>1.697491</td>\n",
       "      <td>-0.350812</td>\n",
       "      <td>-0.302650</td>\n",
       "      <td>-0.284985</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9203</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.174668</td>\n",
       "      <td>-0.759931</td>\n",
       "      <td>1.542214</td>\n",
       "      <td>1.058053</td>\n",
       "      <td>-0.101148</td>\n",
       "      <td>0.960888</td>\n",
       "      <td>3.261643</td>\n",
       "      <td>1.246815</td>\n",
       "      <td>-0.350812</td>\n",
       "      <td>-0.302650</td>\n",
       "      <td>-0.284985</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5127</th>\n",
       "      <td>1</td>\n",
       "      <td>1.249599</td>\n",
       "      <td>0.426773</td>\n",
       "      <td>0.398419</td>\n",
       "      <td>0.671588</td>\n",
       "      <td>1.099572</td>\n",
       "      <td>-0.078415</td>\n",
       "      <td>-0.404731</td>\n",
       "      <td>-1.460658</td>\n",
       "      <td>1.548063</td>\n",
       "      <td>-0.302650</td>\n",
       "      <td>-0.284985</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8921</th>\n",
       "      <td>0</td>\n",
       "      <td>0.306301</td>\n",
       "      <td>-1.060708</td>\n",
       "      <td>0.114295</td>\n",
       "      <td>0.700215</td>\n",
       "      <td>-0.367975</td>\n",
       "      <td>0.129150</td>\n",
       "      <td>-0.428477</td>\n",
       "      <td>-1.563084</td>\n",
       "      <td>0.788513</td>\n",
       "      <td>3.308536</td>\n",
       "      <td>-0.284985</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2129</th>\n",
       "      <td>1</td>\n",
       "      <td>1.603802</td>\n",
       "      <td>-0.738975</td>\n",
       "      <td>-2.046065</td>\n",
       "      <td>-0.490670</td>\n",
       "      <td>-1.168455</td>\n",
       "      <td>-1.335798</td>\n",
       "      <td>-0.379448</td>\n",
       "      <td>1.219501</td>\n",
       "      <td>-0.350812</td>\n",
       "      <td>-0.302650</td>\n",
       "      <td>-0.284985</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      credit_policy  int_rate  installment  log_annual_inc       dti  \\\n",
       "2790              1  1.249599     0.916854       -0.169830 -0.696785   \n",
       "9203              0 -0.174668    -0.759931        1.542214  1.058053   \n",
       "5127              1  1.249599     0.426773        0.398419  0.671588   \n",
       "8921              0  0.306301    -1.060708        0.114295  0.700215   \n",
       "2129              1  1.603802    -0.738975       -2.046065 -0.490670   \n",
       "\n",
       "          fico  days_with_cr_line  revol_bal  revol_util  inq_last_6mths  \\\n",
       "2790 -0.101148          -0.164444  -0.299240    1.697491       -0.350812   \n",
       "9203 -0.101148           0.960888   3.261643    1.246815       -0.350812   \n",
       "5127  1.099572          -0.078415  -0.404731   -1.460658        1.548063   \n",
       "8921 -0.367975           0.129150  -0.428477   -1.563084        0.788513   \n",
       "2129 -1.168455          -1.335798  -0.379448    1.219501       -0.350812   \n",
       "\n",
       "      delinq_2yrs   pub_rec  purpose_all_other  purpose_credit_card  \\\n",
       "2790    -0.302650 -0.284985                  0                    0   \n",
       "9203    -0.302650 -0.284985                  0                    0   \n",
       "5127    -0.302650 -0.284985                  0                    0   \n",
       "8921     3.308536 -0.284985                  0                    0   \n",
       "2129    -0.302650 -0.284985                  0                    0   \n",
       "\n",
       "      purpose_educational  purpose_home_improvement  purpose_major_purchase  \\\n",
       "2790                    0                         0                       0   \n",
       "9203                    0                         0                       0   \n",
       "5127                    0                         0                       0   \n",
       "8921                    0                         0                       0   \n",
       "2129                    1                         0                       0   \n",
       "\n",
       "      purpose_small_business  \n",
       "2790                       1  \n",
       "9203                       0  \n",
       "5127                       1  \n",
       "8921                       0  \n",
       "2129                       0  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_std_auto.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a794aa38-ede6-4e50-bf29-fadd9d841b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "## The above scaler.fit() and scaler.transform() steps can be combined into one:\n",
    "# X_train_std_auto[num_columns] = scaler.fit_transform(X_train_std_auto[num_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fd639322-5370-44b5-858d-85da06ed0ea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is: 60.59%\n",
      "The confusion matrix is:\n",
      "[[180 118]\n",
      " [124 192]]\n"
     ]
    }
   ],
   "source": [
    "# Now let's run the logistic regression again with this standardized data\n",
    "clf.fit(X_train_std_auto,y_train)\n",
    "\n",
    "y_predict = clf.predict(X_test_std_auto)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_predict).round(4)\n",
    "print(f\"The accuracy is: {accuracy:.2%}\")\n",
    "print(\"The confusion matrix is:\")\n",
    "cm = confusion_matrix(y_test, y_predict)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f8fbe5-08d9-44d2-b382-70eee8af8bdd",
   "metadata": {
    "id": "QH0lARRm3XyA"
   },
   "source": [
    "# Summary of lecture \"Modeling and Evaluation with scikit-learn\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1325729b-582a-452d-9eb8-76a8e2959bee",
   "metadata": {
    "id": "QH0lARRm3XyA"
   },
   "source": [
    "To recap, in this lecture we studied:\n",
    "+ (Part 1) How to conduct supervised learning using the `scikit-learn` package. \n",
    "+ (Part 2) A walk-through of several popular supervised learning algorithms.\n",
    "+ (Part 3) Various performance metrics: why many, and when to use each\n",
    "+ (Part 4) Several focused discussions on data wrangling and model performance\n",
    "    + Imputation (embedded in earlier parts; not a standalone discussion)\n",
    "    + Unbalanced data\n",
    "    + Data standardization/normalization    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1179253-6709-4b5f-9197-9d277bde2ed7",
   "metadata": {
    "id": "QH0lARRm3XyA"
   },
   "source": [
    "In addition to learning Python based machine learning, we learned some general guidelines that help us more efficiently plan out our analytical work (rather than unnecessarily wasting time on the wrong paths). For example, we have some ideas on which classifiers to try (and to not try) if performance (interpretability) is the priority. What data wrangling choices have a better chance to help. And so on.\n",
    "\n",
    "That said, by now you should realize that we will also face many questions that *only data can answer*. For example:\n",
    "+ For a random forest, should we set max_depth at 3 or 4 or 5? Should we use 100 trees or 50 trees?\n",
    "+ Should we standardize data before training, or not?\n",
    "\n",
    "Answering the above empirical questions will require us to keep trying and comparing different combinations of model hyperparameters and data wrangling choices. Doing so manually is very time demanding -- in fact, this is what analysts spend a lot of their time on! The good news is that we can use **hyperparameter tuning** to shift a lot of this work to computers, thus significantly cutting down our human-side work. We will study hyperparameter tuning in the next lecture.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
